# 리서치/학습 시 빠지기 쉬운 안티패턴

> AI와 함께 리서치하고 공부할 때 비개발자가 자주 빠지는 함정과 해결법

## 리서치의 90% 문제

AI는 질문을 받으면 빠르게 그럴듯한 답변을 만들어냅니다. 문제는 **그 답변이 진짜인지, 충분한지, 편향되지 않았는지** 확인하지 않을 때 생깁니다. 리서치의 진짜 가치는 AI가 내놓은 첫 답변이 아니라, 그것을 비판적으로 검증하고 통합하는 과정에서 나옵니다.

---

## 안티패턴 목록

### 1. "찾아줘" 증후군

**증상**: "AI에 대해 알아봐줘", "요즘 트렌드 조사해줘"처럼 범위나 목적 없이 막연히 요청
**문제**: AI가 방대한 내용을 얕게 훑어주지만 정작 내가 필요한 부분은 빠지거나, 너무 일반적인 내용만 나옴. 같은 조사를 반복하게 됨
**해결**:
- "누구를 위해", "어떤 결정을 내리기 위해", "어느 수준으로" 질문 설계
- 예시: "찾아줘" → "스타트업 창업자가 Gen AI 도구를 도입할 때 실제로 겪는 문제를 3가지로 정리해줘"
- 조사 목적과 사용할 곳을 먼저 밝히기

### 2. 확증 편향 수용 (Echo Chamber)

**증상**: AI가 자신의 기존 생각을 지지하는 방향으로 대답할 때 그냥 받아들이고, 반대 의견은 물어보지 않음
**문제**: 조사는 했지만 이미 알던 것만 확인하는 결과가 됨. 중요한 반론이나 리스크를 놓침. 마치 자신의 의견에 동의해주는 사람만 만난 것과 같음
**해결**:
- 조사 후 항상 "반대 입장/비판적 관점도 찾아줘" 요청
- "이 결론의 약점이나 한계는 뭐야?" 반드시 추가 질문
- AI는 기본적으로 친절하게 동의하려는 경향이 있음을 인식

### 3. 환각 수용 (Hallucination Acceptance)

**증상**: AI가 자신 있게 제시한 통계, 연구 결과, 인용구, 사람 이름을 팩트체크 없이 그대로 사용
**문제**: AI는 그럴듯하지만 실제로 존재하지 않는 정보를 만들어낼 수 있음. "2023년 MIT 연구에 따르면..."이 실제로는 없는 연구일 수 있음
**해결**:
- 구체적 수치, 연구, 인용은 반드시 "이 정보의 출처를 알려줘" 요청
- 출처를 받았으면 직접 검색해서 실제로 존재하는지 확인
- "이 내용 중 확실하지 않거나 추정인 부분이 있으면 표시해줘" 요청

### 4. 표면 탐색 (Surface Skimming)

**증상**: AI의 첫 번째 답변을 읽고 "아, 이렇구나" 하고 끝냄. 후속 질문을 하지 않음
**문제**: 첫 답변은 보통 개요 수준. 실제로 이해하거나 활용하려면 한 단계 더 파고들어야 하지만, 그냥 넘어감. 빙산의 윗부분만 보고 만족하는 것
**해결**:
- 첫 답변 후 "이 중에서 [가장 중요한 부분]을 더 깊이 설명해줘" 요청
- "이걸 실제로 적용하면 어떻게 돼?" "구체적인 예시를 들어줘" 패턴으로 후속 질문
- 목표: 처음 받은 답변의 2~3배 대화를 이어가기

### 5. 컨텍스트 단절

**증상**: 오늘 조사한 내용을 내일 새 대화에서 언급하지 않고 처음부터 다시 시작. 혹은 이전 조사 결과를 새 질문에 연결하지 않음
**문제**: AI는 이전 대화를 기억하지 못함. 맥락 없이 질문하면 이전 조사와 모순되거나 중복되는 답변이 나옴. 지식이 파편화되어 쌓이지 않음
**해결**:
- 새 대화 시작 시 이전 조사의 핵심 결론을 요약해서 먼저 제공
- "지난번에 알아봤을 때 [결론]이었는데, 이번에는 [새 질문]을 알고 싶어"
- 조사 결과를 별도 문서에 누적해서 다음 대화에 붙여넣기

### 6. 단일 소스 의존

**증상**: AI 하나의 답변만으로 결론을 내림. 다른 관점이나 정보원을 교차 확인하지 않음
**문제**: AI도 학습 데이터의 편향을 가짐. 특정 주제는 학습 데이터가 편중되어 있을 수 있음. 하나의 렌즈로만 보면 전체 그림을 놓침
**해결**:
- 중요한 결론은 "다른 시각이나 다른 전문가 관점도 있어?" 요청
- AI 외에 공식 문서, 논문, 전문가 인터뷰 등 다른 소스로 교차 검증
- "이 주제에서 AI(나)와 다른 의견을 가진 전문가나 관점은?"

### 7. 질문 없는 학습

**증상**: "설명해줘", "알려줘"만 요청하고 이해했는지 확인하거나 "왜?"를 묻지 않음
**문제**: 정보를 받았지만 실제로 이해했는지 모름. 나중에 응용하거나 설명해야 할 때 막힘. 들은 것과 아는 것은 다름
**해결**:
- 설명을 받은 후 "내가 이해한 걸로는 [내 말로 재설명]인데 맞아?" 확인
- "이게 왜 중요해?", "이게 없으면 어떻게 돼?" 등 이유를 묻는 습관
- "이 개념을 초등학생에게 설명한다면?" 요청으로 본질 이해 확인

### 8. 정리 부재

**증상**: 1시간 리서치를 했는데 대화창에만 내용이 있고, 따로 정리한 게 없음. 나중에 뭘 알아봤는지 찾기 어려움
**문제**: 조사한 내용이 흩어지고, 대화 창이 닫히면 사실상 사라짐. 같은 내용을 나중에 또 조사하게 됨. 지식이 누적되지 않음
**해결**:
- 리서치 세션 끝에 "오늘 조사한 내용을 구조화된 요약으로 정리해줘" 요청
- 핵심 결론, 남은 의문점, 다음 단계를 3줄로 정리하는 습관
- 정리된 내용을 별도 문서에 저장하여 지식 누적

---

## 위험 신호 체크리스트

아래 항목 중 3개 이상 해당되면 멈추고 리서치 방식을 점검해야 합니다:

- [ ] AI가 제시한 통계나 수치를 한 번도 검색해서 확인한 적이 없다
- [ ] 오늘 조사한 내용이 어디에도 정리되어 있지 않다
- [ ] "반대 의견도 찾아줘"를 요청한 적이 없다
- [ ] 첫 답변에서 후속 질문 없이 다음 주제로 넘어간다
- [ ] 리서치 결론이 항상 처음 생각과 일치한다
- [ ] 같은 주제를 여러 번 다시 물어본 적이 있다
- [ ] AI가 준 답변을 그대로 다른 사람에게 공유한 적이 있다
- [ ] 출처를 물어봤지만 그 출처를 실제로 클릭해서 확인하지 않았다

---

## 출처 및 참고

- [Stanford d.school - Design Thinking Research Methods](https://dschool.stanford.edu/)
- [CRAAP Test for Source Evaluation (California State University)](https://library.csuchico.edu/help/source-or-information-good)
- [AI Hallucination Overview (IBM)](https://www.ibm.com/think/topics/ai-hallucinations)
- [Confirmation Bias in Research (Psychology Today)](https://www.psychologytoday.com/us/basics/confirmation-bias)
